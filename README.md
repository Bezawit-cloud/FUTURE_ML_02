# ğŸ“ Telecom Churn Predictor ğŸš€  
### âš¡ **Keeping customers is more valuable than acquiring new ones.**

In the telecom industry, companies spend millions acquiring customers â€” but many still leave for competitors.  
This loss, called **customer churn**, directly affects a companyâ€™s growth and revenue.

Imagine a telecom provider losing 5% of its customers every month.  
What if it could **predict whoâ€™s likely to leave next**, and intervene before that happens?

This project tackles that challenge by building an intelligent **machine learning model** that predicts customer churn based on service usage, contract type, and demographic data â€” helping telecoms make proactive retention decisions.

## ğŸ¯ **Live Demo**
ğŸ‘‰ [**Launch Streamlit App**](#)  
*(https://futureml02-ywxtwftgrdivqguw3uuxfr.streamlit.app/)*  

---

## ğŸ–¼ï¸ **Screenshots**

|  EDA Visualization |
| :------------: | :---------------: |
| ![ Correlation map]("C:\Users\bezis\OneDrive\Pictures\Screenshots\Screenshot 2025-10-24 095351.png") | ![EDA Screenshot]("C:\Users\bezis\OneDrive\Pictures\Screenshots\Screenshot 2025-10-24 095520.png") |

## ğŸ§© **Overview**
This project predicts **customer churn** for a telecom company using machine learning.  
The workflow includes:
- Data preprocessing  
- Exploratory Data Analysis (EDA)  
- Handling unbalanced data using **SMOTE**  
- Comparing multiple ML models (Random Forest vs XGBoost)  
- Selecting the best model for deployment via **Streamlit**

## âš™ï¸ **Workflow & Methodology**

### ğŸ§¹ Data Cleaning & Preprocessing
- Removed unnecessary columns  
- Converted `TotalCharges` to float  
- Filled missing values  
- Encoded categorical columns using LabelEncoder  

### ğŸ” Exploratory Data Analysis (EDA)
- Correlation heatmap for relationships  
- Boxplots to detect outliers  
- Visualized service usage vs churn  
- Distribution analysis of tenure, contracts, and payment methods  

### âš–ï¸ Handling Class Imbalance
- Detected imbalance in `Churn` column  
- Applied **SMOTE (Synthetic Minority Oversampling Technique)**  
- Balanced dataset improved recall for minority class  

### ğŸ¤– Model Building & Comparison
- Trained and compared **Random Forest** and **XGBoost** classifiers  
- Used 80/20 train-test split  
- Evaluated performance using **Accuracy**, **Precision**, **Recall**, and **F1-Score**

---

## ğŸ“Š **Model Evaluation**

| Metric | Random Forest | XGBoost |
|:--------|:--------------:|:-------:|
| Accuracy | 0.82 | **0.86** |
| Precision | 0.79 | **0.84** |
| Recall | 0.77 | **0.85** |
| F1-Score | 0.78 | **0.85** |

- XGBoost performed best overall and was chosen for final deployment  
- A **confusion matrix** and **classification report** supported this selection  

## ğŸš€ **Model Deployment**

After selecting the best-performing model (XGBoost):  
1. The trained model and encoders were **saved using `pickle`**:  
   - `customer_churn_model.pkl` â†’ trained model  
   - `encoders.pkl` â†’ label encoders for categorical data  
2. The Streamlit app (`streamlit_app.py`) loads these files to perform live predictions.  
3. Inputs from users are encoded and aligned with the training features.  
4. The model predicts whether a customer will **Stay âœ…** or **Churn ğŸš¨**.  
5. Deployed to **Streamlit Cloud** for easy public access.

  
## ğŸŒŸ **Key Features**
âœ… Predicts if a customer will **Stay** or **Churn**  
âœ… Displays **churn probability score** for better understanding  
âœ… Integrates **EDA insights** visually  
âœ… Handles both **categorical and numerical data**  
âœ… Deployable on **Streamlit Cloud or Heroku**

feature_names = model_data["features_names"]

